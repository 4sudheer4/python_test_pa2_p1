{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled12.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdQippI4p/ahgqY4L1ptop",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4sudheer4/python_test_pa2_p1/blob/main/colab_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODHVVzU8h-1n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(\"Num GPUs Available: \", len(physical_devices))\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "metadata": {
        "id": "hqpmuwnwF2kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "setattr(tfds.image_classification.cats_vs_dogs, '_URL',\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\")\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "train_ds, validation_ds, test_ds = tfds.load(\n",
        "    \"cats_vs_dogs\",\n",
        "    # Reserve 10% for validation and 10% for test\n",
        "    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n",
        "    as_supervised=True  # Include labels\n",
        ")\n",
        "\n",
        "print(\"Number of training samples: %d\" % tf.data.experimental.cardinality(train_ds))\n",
        "print(\n",
        "    \"Number of validation samples: %d\" % tf.data.experimental.cardinality(validation_ds)\n",
        ")\n",
        "print(\"Number of test samples: %d\" % tf.data.experimental.cardinality(test_ds))\n"
      ],
      "metadata": {
        "id": "mx6FsU-UF5vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i, (image, label) in enumerate(train_ds.take(9)):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(int(label))\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "ZIDhdnw7IcFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = (150, 150)\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
        "validation_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
        "test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n"
      ],
      "metadata": {
        "id": "TG7tM8HDId8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
        "validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
        "test_ds = test_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n"
      ],
      "metadata": {
        "id": "Rei7EmtKI4lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "6UaLwJG3I5LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "for images, labels in train_ds.take(1):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    first_image = images[0]\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        augmented_image = data_augmentation(\n",
        "            tf.expand_dims(first_image, 0), training=True\n",
        "        )\n",
        "        plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
        "        plt.title(int(labels[i]))\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "2C_N-X3oI_74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.VGG16(\n",
        "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(150, 150, 3),\n",
        "    include_top=False\n",
        ")  # Do not include the ImageNet classifier at the top.\n",
        "\n",
        "# Freeze the base_model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create new model on top\n",
        "inputs = keras.Input(shape=(150, 150, 3))\n",
        "x = data_augmentation(inputs)  # Apply random data augmentation\n",
        "\n",
        "# Pre-trained Xception weights requires that input be normalized\n",
        "# from (0, 255) to a range (-1., +1.), the normalization layer\n",
        "# does the following, outputs = (inputs - mean) / sqrt(var)\n",
        "norm_layer = keras.layers.experimental.preprocessing.Normalization()\n",
        "mean = np.array([127.5] * 3)\n",
        "var = mean ** 2\n",
        "# Scale inputs to [-1, +1]\n",
        "x = norm_layer(x)\n",
        "#norm_layer.set_weights([mean,var])\n",
        "\n",
        "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "# base_model is running in inference mode here.\n",
        "x = base_model(x, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "outputs = keras.layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "e8BAwKt5JAWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "epochs = 3\n",
        "model.fit(train_ds, epochs=epochs, validation_data=validation_ds)"
      ],
      "metadata": {
        "id": "aMWv6gEPJDi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
        "# since we passed `training=False` when calling it. This means that\n",
        "# the batchnorm layers will not update their batch statistics.\n",
        "# This prevents the batchnorm layers from undoing all the training\n",
        "# we've done so far.\n",
        "base_model.trainable = True\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "epochs = 2\n",
        "model.fit(train_ds, epochs=epochs, validation_data=validation_ds)"
      ],
      "metadata": {
        "id": "15DDssiFK5yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_ds)\n"
      ],
      "metadata": {
        "id": "e2di2fRALVKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.evaluate(x=test_ds))\n"
      ],
      "metadata": {
        "id": "KSj-NZ7OMbab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals\n",
        "!pip install youtube_dl\n",
        "\n",
        "import youtube_dl\n",
        "\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'bestaudio/best',\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'mp3',\n",
        "        'preferredquality': '192',\n",
        "    }],\n",
        "}\n",
        "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download(['https://www.youtube.com/watch?v=sRdRwHPjJPk'])\n",
        "    ydl.download(['https://www.youtube.com/watch?v=PPdNb-XQXR8'])\n",
        "# for bike sounds : https://www.youtube.com/watch?v=sRdRwHPjJPk\n",
        "# for car sounds : https://www.youtube.com/watch?v=PPdNb-XQXR8"
      ],
      "metadata": {
        "id": "tHcSi4143VnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "from pydub import AudioSegment\n",
        "sound = AudioSegment.from_mp3(\"bikers.mp3\")\n",
        "sound.export(\"bikers.wav\", format=\"wav\")"
      ],
      "metadata": {
        "id": "pppj-7Lc3WkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import os\n",
        "if not os.path.exists(\"bikers\"):\n",
        "    os.makedirs(\"bikers\")\n",
        "\n",
        "count=1\n",
        "for i in range(1,1000,15):\n",
        "    t1 = i * 1000 #Works in milliseconds\n",
        "    t2 = (i+15) * 1000\n",
        "    newAudio = AudioSegment.from_wav(\"bikers.wav\")\n",
        "    newAudio = newAudio[t1:t2]\n",
        "    #newAudio.export('bike/'+str(count)+'.wav', format=\"wav\") #Exports to a wav file in the current path.\n",
        "    print(count)\n",
        "    count+=1"
      ],
      "metadata": {
        "id": "hyZtpXGwAYIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libportaudio2\n",
        "!pip install sounddevice"
      ],
      "metadata": {
        "id": "iwt3qGyi4CZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = AudioSet(root='/data/AudioSet', include=['Thunderstorm'])\n",
        "print(data)"
      ],
      "metadata": {
        "id": "bRUYB_OP4ajl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "bluLeK0fXcHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "with open('sample_data', 'w') as f:\n",
        "  f.write('sample_data')\n",
        "\n",
        "files.download('sample_data')"
      ],
      "metadata": {
        "id": "Q_5d5ISZXjOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat /content/drive/My\\ Drive/foo.txt"
      ],
      "metadata": {
        "id": "-hnLEIdQZp7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()\n"
      ],
      "metadata": {
        "id": "aaHdtVyCajmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aoifemcdonagh/audioset-processing.git"
      ],
      "metadata": {
        "id": "0ouN9RPma1Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd audioset-processing/"
      ],
      "metadata": {
        "id": "ka_p7JEta7G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "metadata": {
        "id": "3B5C80Iaa8Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "v9StNEiXa-uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "UyPES8cBbB9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IHrL00wFbMYX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}